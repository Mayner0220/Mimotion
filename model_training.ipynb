{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import import_ipynb\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import layers\n",
    "from data_preprocessing import train_ds, val_ds\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(48, 3, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(48, 3, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(48, 3, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(2304, activation=\"relu\"),\n",
    "    layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "start_time = datetime.now().strftime(\"%Y-&m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002544D227AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002544D227AE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  2/359 [..............................] - ETA: 1:38 - loss: 56.5088 - accuracy: 0.1797WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0100s vs `on_train_batch_end` time: 0.5418s). Check your callbacks.\n",
      "359/359 [==============================] - ETA: 0s - loss: 2.7931 - accuracy: 0.2611 ETA: 0s - loss: 2.8015 - accuracy: 0.26WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002544E3F4268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002544E3F4268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.77114, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 8s 21ms/step - loss: 2.7931 - accuracy: 0.2611 - val_loss: 1.7711 - val_accuracy: 0.2585\n",
      "Epoch 2/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.7393 - accuracy: 0.3006WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.77114 to 1.73078, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.7392 - accuracy: 0.3007 - val_loss: 1.7308 - val_accuracy: 0.2767\n",
      "Epoch 3/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.6950 - accuracy: 0.3247WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.73078 to 1.69401, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.6950 - accuracy: 0.3247 - val_loss: 1.6940 - val_accuracy: 0.3010\n",
      "Epoch 4/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.6523 - accuracy: 0.3472WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.69401 to 1.65482, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 1.6526 - accuracy: 0.3470 - val_loss: 1.6548 - val_accuracy: 0.3324\n",
      "Epoch 5/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.6129 - accuracy: 0.3698WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.65482 to 1.60569, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 1.6129 - accuracy: 0.3697 - val_loss: 1.6057 - val_accuracy: 0.3582\n",
      "Epoch 6/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.5633 - accuracy: 0.3890WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.60569 to 1.55751, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.5633 - accuracy: 0.3889 - val_loss: 1.5575 - val_accuracy: 0.4014\n",
      "Epoch 7/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.5139 - accuracy: 0.4104WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.55751 to 1.51313, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.5138 - accuracy: 0.4103 - val_loss: 1.5131 - val_accuracy: 0.3986\n",
      "Epoch 8/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.4754 - accuracy: 0.4249 ETA: 2s -WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.51313 to 1.45966, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 1.4753 - accuracy: 0.4250 - val_loss: 1.4597 - val_accuracy: 0.4348\n",
      "Epoch 9/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.4236 - accuracy: 0.4475 ETA: 1sWARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.45966\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 1.4232 - accuracy: 0.4477 - val_loss: 1.4685 - val_accuracy: 0.4258\n",
      "Epoch 10/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.3643 - accuracy: 0.4757WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.45966 to 1.40042, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 1.3639 - accuracy: 0.4757 - val_loss: 1.4004 - val_accuracy: 0.4544\n",
      "Epoch 11/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.3170 - accuracy: 0.4984 ETA: 0s - loss: 1.313WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.40042\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.3169 - accuracy: 0.4985 - val_loss: 1.4118 - val_accuracy: 0.4460\n",
      "Epoch 12/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.2590 - accuracy: 0.5225 ETA: 0s - loss: 1.2581 - acWARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.40042 to 1.37882, saving model to models\\2020-&m-09_19-45-05.h5\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 1.2584 - accuracy: 0.5227 - val_loss: 1.3788 - val_accuracy: 0.4655\n",
      "Epoch 13/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.1995 - accuracy: 0.5484WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_loss did not improve from 1.37882\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 1.1990 - accuracy: 0.5485 - val_loss: 1.3893 - val_accuracy: 0.4760\n",
      "Epoch 14/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.1405 - accuracy: 0.5739WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.37882\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 1.1398 - accuracy: 0.5741 - val_loss: 1.3851 - val_accuracy: 0.4585\n",
      "Epoch 15/100\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.1168 - accuracy: 0.5878WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.37882\n",
      "359/359 [==============================] - 7s 20ms/step - loss: 1.1168 - accuracy: 0.5878 - val_loss: 1.4050 - val_accuracy: 0.4578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2544cf1e550>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=100,\n",
    "         callbacks=[\n",
    "             ReduceLROnPlateau(monitor=\"val_lose\", factor=0.2, patience=10, verbose=1, mode=\"auto\", min_lr=1e-05),\n",
    "             ModelCheckpoint(\"models/%s.h5\" % (start_time), monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1),\n",
    "             TensorBoard(log_dir=\"logs/%s\" % (start_time)),\n",
    "             EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "         ],\n",
    "          use_multiprocessing=True,\n",
    "          workers=5,\n",
    "          max_queue_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
