{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import import_ipynb\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import layers\n",
    "from data_preprocessing import train_ds, val_ds\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(48, 3, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(48, 3, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(48, 3, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(2304, activation=\"softmax\"),\n",
    "    layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# [\"accuracy\"]\n",
    "model.compile(optimizer=\"adam\", loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "start_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EA13098378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001EA13098378> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/718 [..............................] - ETA: 0s - loss: 1.9437 - accuracy: 0.1250WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/718 [..............................] - ETA: 26s - loss: 1.9486 - accuracy: 0.1562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0060s vs `on_train_batch_end` time: 0.0661s). Check your callbacks.\n",
      "718/718 [==============================] - ETA: 0s - loss: 1.8677 - accuracy: 0.2436WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001E93C55FF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001E93C55FF28> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.83716, saving model to models\\2020-10-10_23-01-38.h5\n",
      "718/718 [==============================] - 31s 43ms/step - loss: 1.8677 - accuracy: 0.2436 - val_loss: 1.8372 - val_accuracy: 0.2425\n",
      "Epoch 2/100\n",
      "716/718 [============================>.] - ETA: 0s - loss: 1.8231 - accuracy: 0.2486 ETA: 0s - loss: 1.8229 WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.83716 to 1.81430, saving model to models\\2020-10-10_23-01-38.h5\n",
      "718/718 [==============================] - 8s 11ms/step - loss: 1.8230 - accuracy: 0.2488 - val_loss: 1.8143 - val_accuracy: 0.2425\n",
      "Epoch 3/100\n",
      "717/718 [============================>.] - ETA: 0s - loss: 1.8125 - accuracy: 0.2487WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.81430 to 1.81090, saving model to models\\2020-10-10_23-01-38.h5\n",
      "718/718 [==============================] - 8s 11ms/step - loss: 1.8124 - accuracy: 0.2488 - val_loss: 1.8109 - val_accuracy: 0.2425\n",
      "Epoch 4/100\n",
      "716/718 [============================>.] - ETA: 0s - loss: 1.8114 - accuracy: 0.2486WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.81090 to 1.81011, saving model to models\\2020-10-10_23-01-38.h5\n",
      "718/718 [==============================] - 8s 11ms/step - loss: 1.8114 - accuracy: 0.2488 - val_loss: 1.8101 - val_accuracy: 0.2425\n",
      "Epoch 5/100\n",
      "716/718 [============================>.] - ETA: 0s - loss: 1.8113 - accuracy: 0.2486WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.81011 to 1.80987, saving model to models\\2020-10-10_23-01-38.h5\n",
      "718/718 [==============================] - 8s 11ms/step - loss: 1.8112 - accuracy: 0.2488 - val_loss: 1.8099 - val_accuracy: 0.2425\n",
      "Epoch 6/100\n",
      "235/718 [========>.....................] - ETA: 5s - loss: 1.8029 - accuracy: 0.2496"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=100,\n",
    "         callbacks=[\n",
    "             ReduceLROnPlateau(monitor=\"val_lose\", factor=0.2, patience=10, verbose=1, mode=\"auto\", min_lr=1e-05),\n",
    "             ModelCheckpoint(\"models/%s.h5\" % (start_time), monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1),\n",
    "             TensorBoard(log_dir=\"logs/%s\" % (start_time)),\n",
    "             EarlyStopping(monitor=\"val_loss\", patience=3)\n",
    "         ],\n",
    "          use_multiprocessing=True,\n",
    "          workers=5,\n",
    "          max_queue_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
