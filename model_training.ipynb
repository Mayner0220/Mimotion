{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import import_ipynb\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import layers\n",
    "from data_preprocessing import train_ds, val_ds\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(48, 3, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(48, 3, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(48, 3, activation=\"relu\"),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(2304, activation=\"relu\"),\n",
    "    layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "start_time = datetime.now().strftime(\"%Y-&m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002544C6D9EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002544C6D9EA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "  1/359 [..............................] - ETA: 0s - loss: 22.0478 - accuracy: 0.1719WARNING:tensorflow:From c:\\users\\user\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/359 [..............................] - ETA: 23s - loss: 60.8902 - accuracy: 0.1719WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0165s vs `on_train_batch_end` time: 0.1170s). Check your callbacks.\n",
      "359/359 [==============================] - ETA: 0s - loss: 3.6319 - accuracy: 0.2458WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002544C8182F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002544C8182F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.80605, saving model to models\\2020-&m-08_20-20-11.h5\n",
      "359/359 [==============================] - 8s 22ms/step - loss: 3.6319 - accuracy: 0.2458 - val_loss: 1.8061 - val_accuracy: 0.2481\n",
      "Epoch 2/10\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.8105 - accuracy: 0.2517WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.80605\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.8104 - accuracy: 0.2516 - val_loss: 1.8073 - val_accuracy: 0.2474\n",
      "Epoch 3/10\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.8085 - accuracy: 0.2531WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.80605 to 1.80530, saving model to models\\2020-&m-08_20-20-11.h5\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.8085 - accuracy: 0.2530 - val_loss: 1.8053 - val_accuracy: 0.2509\n",
      "Epoch 4/10\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.8066 - accuracy: 0.2526WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.80530\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.8066 - accuracy: 0.2526 - val_loss: 1.8073 - val_accuracy: 0.2516\n",
      "Epoch 5/10\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.8062 - accuracy: 0.2538WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.80530\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.8062 - accuracy: 0.2537 - val_loss: 1.8105 - val_accuracy: 0.2467\n",
      "Epoch 6/10\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.8035 - accuracy: 0.2566WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.80530 to 1.80290, saving model to models\\2020-&m-08_20-20-11.h5\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.8036 - accuracy: 0.2564 - val_loss: 1.8029 - val_accuracy: 0.2523\n",
      "Epoch 7/10\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.8033 - accuracy: 0.2565WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.80290\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.8035 - accuracy: 0.2564 - val_loss: 1.8110 - val_accuracy: 0.2432\n",
      "Epoch 8/10\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.8034 - accuracy: 0.2547 ETA: 1s - loss: 1WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.80290\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.8033 - accuracy: 0.2546 - val_loss: 1.8201 - val_accuracy: 0.2460\n",
      "Epoch 9/10\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.8012 - accuracy: 0.2562WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.80290\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.8012 - accuracy: 0.2561 - val_loss: 1.8166 - val_accuracy: 0.2432\n",
      "Epoch 10/10\n",
      "358/359 [============================>.] - ETA: 0s - loss: 1.8038 - accuracy: 0.2554WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_lose` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.80290\n",
      "359/359 [==============================] - 7s 19ms/step - loss: 1.8037 - accuracy: 0.2554 - val_loss: 1.8060 - val_accuracy: 0.2481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2544c6e0400>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=10,\n",
    "         callbacks=[\n",
    "             ReduceLROnPlateau(monitor=\"val_lose\", factor=0.2, patience=10, verbose=1, mode=\"auto\", min_lr=1e-05),\n",
    "             ModelCheckpoint(\"models/%s.h5\" % (start_time), monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1),\n",
    "             TensorBoard(log_dir=\"logs/%s\" % (start_time))\n",
    "         ],\n",
    "          use_multiprocessing=True,\n",
    "          workers=5,\n",
    "          max_queue_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
