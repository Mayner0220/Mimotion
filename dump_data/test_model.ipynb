{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameter\n",
    "batch_size = 32\n",
    "img_height = 48\n",
    "img_width = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNC(func):\n",
    "    return tf.autograph.experimental.do_not_convert(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset dir path\n",
    "train_data_dir = \"./dataset/train\"\n",
    "test_data_dir = \"./dataset/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Using 22968 files for training.\n"
     ]
    }
   ],
   "source": [
    "# Get train dataset\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_data_dir,\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use tf.autograph.experimental.do_not_convert() to suppresses warnings\n",
    "train_nor_dataset = train_dataset.map(DNC(\n",
    "    lambda x, y: (normalization_layer(x), y)))\n",
    "test_nor_dataset = test_dataset.map(DNC(\n",
    "    lambda x, y: (normalization_layer(x), y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.experimental.preprocessing.Rescaling(1./225, input_shape=(img_height, img_width, 1)),\n",
    "    \n",
    "    layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=sgd,\n",
    "             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_1 (Rescaling)      (None, 48, 48, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 48, 48, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 319,239\n",
      "Trainable params: 319,239\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"models\", exist_ok=True)\n",
    "start_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4934 - accuracy: 0.8241\n",
      "Epoch 2/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4900 - accuracy: 0.8231\n",
      "Epoch 3/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4928 - accuracy: 0.8255\n",
      "Epoch 4/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4938 - accuracy: 0.8259\n",
      "Epoch 5/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4817 - accuracy: 0.82820s - loss: 0.4851 - ac\n",
      "Epoch 6/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.5014 - accuracy: 0.8224\n",
      "Epoch 7/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4778 - accuracy: 0.8303\n",
      "Epoch 8/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4854 - accuracy: 0.8301\n",
      "Epoch 9/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4778 - accuracy: 0.8316\n",
      "Epoch 10/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4697 - accuracy: 0.8336\n",
      "Epoch 11/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4744 - accuracy: 0.8326\n",
      "Epoch 12/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4712 - accuracy: 0.83330s - loss: 0\n",
      "Epoch 13/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4414 - accuracy: 0.84070s - loss: 0\n",
      "Epoch 14/50\n",
      "718/718 [==============================] - ETA: 0s - loss: 0.4674 - accuracy: 0.83 - 16s 22ms/step - loss: 0.4673 - accuracy: 0.8339\n",
      "Epoch 15/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4493 - accuracy: 0.8415\n",
      "Epoch 16/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4475 - accuracy: 0.84281s - loss: 0.449 - ETA: 0s - loss:\n",
      "Epoch 17/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4497 - accuracy: 0.84401s -\n",
      "Epoch 18/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4401 - accuracy: 0.8484\n",
      "Epoch 19/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4474 - accuracy: 0.8427\n",
      "Epoch 20/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4384 - accuracy: 0.8471\n",
      "Epoch 21/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4505 - accuracy: 0.8415\n",
      "Epoch 22/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4161 - accuracy: 0.8524\n",
      "Epoch 23/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4471 - accuracy: 0.8430\n",
      "Epoch 24/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4444 - accuracy: 0.8466\n",
      "Epoch 25/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4306 - accuracy: 0.84801s - loss: 0 - ETA: 1s - l\n",
      "Epoch 26/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4395 - accuracy: 0.8471\n",
      "Epoch 27/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4368 - accuracy: 0.84810s - loss: 0.4364 - accuracy: 0.84\n",
      "Epoch 28/50\n",
      "718/718 [==============================] - 16s 23ms/step - loss: 0.4211 - accuracy: 0.8515\n",
      "Epoch 29/50\n",
      "718/718 [==============================] - 16s 23ms/step - loss: 0.4013 - accuracy: 0.8602\n",
      "Epoch 30/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4200 - accuracy: 0.8540\n",
      "Epoch 31/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4131 - accuracy: 0.8574\n",
      "Epoch 32/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4208 - accuracy: 0.8566\n",
      "Epoch 33/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4245 - accuracy: 0.8534\n",
      "Epoch 34/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4076 - accuracy: 0.8595\n",
      "Epoch 35/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4183 - accuracy: 0.85510s - loss: 0.4184 - \n",
      "Epoch 36/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4060 - accuracy: 0.86001s - loss: 0.4105  - ETA: 0s - loss:\n",
      "Epoch 37/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4085 - accuracy: 0.8609\n",
      "Epoch 38/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4055 - accuracy: 0.8585\n",
      "Epoch 39/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3995 - accuracy: 0.8615\n",
      "Epoch 40/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3905 - accuracy: 0.8674\n",
      "Epoch 41/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3977 - accuracy: 0.8620\n",
      "Epoch 42/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3953 - accuracy: 0.86380s - loss: 0.3958 - \n",
      "Epoch 43/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.4076 - accuracy: 0.86031s - loss: 0.4081 - accuracy:  - ETA: 0s - los\n",
      "Epoch 44/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3983 - accuracy: 0.8612\n",
      "Epoch 45/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3931 - accuracy: 0.86511s\n",
      "Epoch 46/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3884 - accuracy: 0.86670s - loss: 0.3877 - ac\n",
      "Epoch 47/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3949 - accuracy: 0.8635\n",
      "Epoch 48/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3929 - accuracy: 0.8640\n",
      "Epoch 49/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3694 - accuracy: 0.8747\n",
      "Epoch 50/50\n",
      "718/718 [==============================] - 16s 22ms/step - loss: 0.3967 - accuracy: 0.8657\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "#         DNC(ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=10, verbose=1, mode=\"auto\", min_lr=1e-05)),\n",
    "#         DNC(ModelCheckpoint(\"models/%s.h5\" % (start_time), monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1)),\n",
    "#         DNC(TensorBoard(log_dir=\"logs/%s\" % (start_time))),\n",
    "#         DNC(EarlyStopping(monitor=\"val_loss\", patience=3))\n",
    "    ],\n",
    "    use_multiprocessing=True,\n",
    "    workers=5,\n",
    "    max_queue_size=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 4s 19ms/step - loss: 2.1102 - accuracy: 0.5177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.110214948654175, 0.5176929235458374]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
